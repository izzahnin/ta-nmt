{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef7b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Selesai! Total data: 11788\n",
      "üì¶ File disimpan di: ./translated_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "SOURCE_DIR = r'd:\\DATA CACA\\00. College\\Skripsi\\ta_nmt\\text_c10_translated_gt'\n",
    "OUTPUT_FILE = './translated_dataset.json'\n",
    "\n",
    "# Ambil daftar folder kelas dan urutkan\n",
    "class_folders = sorted([\n",
    "    folder for folder in os.listdir(SOURCE_DIR)\n",
    "    if os.path.isdir(os.path.join(SOURCE_DIR, folder))\n",
    "])\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# Proses tiap folder\n",
    "for class_id, class_folder in enumerate(class_folders):\n",
    "    folder_path = os.path.join(SOURCE_DIR, class_folder)\n",
    "    txt_files = sorted(glob(os.path.join(folder_path, '*.txt')))\n",
    "\n",
    "    for txt_path in txt_files:\n",
    "        try:\n",
    "            with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "            item = {\n",
    "                \"filename\": os.path.basename(txt_path).replace('.txt', '.jpg'),\n",
    "                \"class_name\": class_folder,\n",
    "                \"class_id\": class_id,\n",
    "                \"captions\": lines\n",
    "            }\n",
    "            all_data.append(item)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading {txt_path}: {e}\")\n",
    "\n",
    "# Simpan hasil akhir ke file JSON\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Selesai! Total data: {len(all_data)}\")\n",
    "print(f\"üì¶ File disimpan di: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69994aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\DATA CACA\\00. College\\Skripsi\\ta_nmt\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6670af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gabungan selesai. Total item: 11788\n",
      "üìÅ Disimpan di: ./merged_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# MERGED/gabung class*.json\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "SOURCE_DIR = r'd:\\DATA CACA\\00. College\\Skripsi\\ta_nmt\\paralel_disempurnakan'\n",
    "OUTPUT_FILE = './merged_dataset.json'\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# Ambil semua file class_*.json\n",
    "json_paths = sorted(glob(os.path.join(SOURCE_DIR, 'class_*.json')))\n",
    "\n",
    "for path in json_paths:\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if \"dataset\" in data:\n",
    "            all_data.extend(data[\"dataset\"])\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  File tanpa key 'dataset': {path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Gagal memproses {path}: {e}\")\n",
    "\n",
    "# Simpan hasil gabungan\n",
    "output = {\n",
    "    \"dataset\": all_data\n",
    "}\n",
    "\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Gabungan selesai. Total item: {len(all_data)}\")\n",
    "print(f\"üìÅ Disimpan di: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46555975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total data: 11788\n",
      "üìÅ File disimpan ke: ./paralel_cub_200_2011_indo_only.json\n"
     ]
    }
   ],
   "source": [
    "# mengambil hanya caption bahasa Indonesia dari dataset gabungan\n",
    "import json\n",
    "\n",
    "# === Path konfigurasi ===\n",
    "# INPUT_FILE = r'd:\\DATA CACA\\00. College\\Skripsi\\ta_nmt\\notebooks\\merged_dataset.json'\n",
    "INPUT_FILE = r'd:\\DATA CACA\\00. College\\Skripsi\\ta_nmt\\data\\paralel_cub_200_2011_captions.json'\n",
    "OUTPUT_FILE = './paralel_cub_200_2011_indo_only.json'\n",
    "\n",
    "# Daftar class_name (ganti dengan isi class sebenarnya!)\n",
    "with open('classes.txt', 'r', encoding='utf-8') as f:\n",
    "    class_names = [line.strip() for line in f]\n",
    "\n",
    "\n",
    "# Baca file JSON gabungan\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "result = []\n",
    "\n",
    "for item in data.get(\"dataset\", []):\n",
    "    captions = item.get(\"captions\", [])\n",
    "    indo_only = [cap[\"indo\"] for cap in captions if isinstance(cap, dict) and \"indo\" in cap]\n",
    "\n",
    "    result.append({\n",
    "        \"filename\": item[\"filename\"],\n",
    "        \"class_id\": item[\"class_id\"],\n",
    "        \"class_name\": class_names[item[\"class_id\"]],\n",
    "        \"captions\": indo_only\n",
    "    })\n",
    "\n",
    "print(f\"‚úÖ Total data: {len(result)}\")\n",
    "\n",
    "# Simpan hasilnya\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"üìÅ File disimpan ke: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b2e5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Contoh class_names[0:5]:\n",
      "000 ‚Üí 001.Black_footed_Albatross\n",
      "001 ‚Üí 002.Laysan_Albatross\n",
      "002 ‚Üí 003.Sooty_Albatross\n",
      "003 ‚Üí 004.Groove_billed_Ani\n",
      "004 ‚Üí 005.Crested_Auklet\n",
      "\n",
      "üìÅ Disimpan ke: ./classes.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path ke file JSON yang berisi data \"class\"\n",
    "CLASS_FILE = r'd:\\DATA CACA\\00. College\\Skripsi\\ta_nmt\\data\\paralel_cub_200_2011_captions.json'\n",
    "OUTPUT_TXT = './classes.txt'          # Opsional: simpan ke file .txt\n",
    "\n",
    "# Load JSON\n",
    "with open(CLASS_FILE, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Ambil list class name sesuai urutan id\n",
    "class_names = [None] * len(data[\"class\"])\n",
    "for entry in data[\"class\"]:\n",
    "    class_names[entry[\"id\"]] = entry[\"class\"]\n",
    "\n",
    "# Tampilkan sebagian hasil\n",
    "print(\"‚úÖ Contoh class_names[0:5]:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i:03d} ‚Üí {class_names[i]}\")\n",
    "\n",
    "# Simpan ke file teks jika mau\n",
    "with open(OUTPUT_TXT, 'w', encoding='utf-8') as f:\n",
    "    for name in class_names:\n",
    "        f.write(name + '\\n')\n",
    "\n",
    "print(f\"\\nüìÅ Disimpan ke: {OUTPUT_TXT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbcec7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data berhasil disusun ulang dan disimpan ke: ./indo_captions_only.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "INPUT_FILE = './indo_captions_only.json'\n",
    "OUTPUT_FILE = './indo_captions_only.json'\n",
    "\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Susun ulang urutan key di setiap item\n",
    "reordered_data = []\n",
    "for item in data:\n",
    "    reordered_item = {\n",
    "        \"filename\": item.get(\"filename\"),\n",
    "        \"class_name\": item.get(\"class_name\"),\n",
    "        \"class_id\": item.get(\"class_id\"),\n",
    "        \"captions\": item.get(\"captions\", [])\n",
    "    }\n",
    "    reordered_data.append(reordered_item)\n",
    "\n",
    "# Simpan ke file baru\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(reordered_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Data berhasil disusun ulang dan disimpan ke: {OUTPUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
